import re
import numpy as np
import pandas as pd
import streamlit as st
from pathlib import Path
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import unicodedata

# --- C·∫•u h√¨nh trang v√† ti√™u ƒë·ªÅ ---
st.set_page_config(page_title="ƒê·ªì √Ån T·ªët Nghi·ªáp - Project 2", layout="wide", page_icon="üè®")

# --- C√°c h√†m t·∫£i v√† x·ª≠ l√Ω d·ªØ li·ªáu (v·ªõi cache ƒë·ªÉ t·ªëi ∆∞u hi·ªáu su·∫•t) ---

@st.cache_data
def load_data():
    """T·∫£i d·ªØ li·ªáu t·ª´ file CSV m·ªôt c√°ch an to√†n v√† cache l·∫°i."""
    def read_csv_safely(path, **kwargs):
        for enc in ["utf-8", "utf-8-sig", "cp1258", "latin-1"]:
            try:
                return pd.read_csv(path, encoding=enc, **kwargs)
            except Exception:
                pass
        raise ValueError(f"Kh√¥ng th·ªÉ ƒë·ªçc file {path} v·ªõi c√°c encoding ƒë√£ th·ª≠.")

    data_dir = Path("./data/")
    hotel_info = read_csv_safely(data_dir / "hotel_info.csv")
    
    # X√°c ƒë·ªãnh c√°c c·ªôt quan tr·ªçng m·ªôt c√°ch linh ho·∫°t
    id_cols = [c for c in hotel_info.columns if "Hotel_ID" in c]
    name_cols = [c for c in hotel_info.columns if "Hotel_Name" in c]
    
    hotel_id_col = id_cols[0] if id_cols else hotel_info.columns[0]
    hotel_name_col = name_cols[0] if name_cols else hotel_info.columns[1]
    
    return hotel_info, hotel_id_col, hotel_name_col

@st.cache_resource
def preprocess_and_tfidf(hotel_info, hotel_id_col, hotel_name_col):
    """Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n v√† t√≠nh to√°n ma tr·∫≠n t∆∞∆°ng ƒë·ªìng TF-IDF."""
    def simple_clean(s):
        if not isinstance(s, str): s = str(s)
        s = unicodedata.normalize("NFC", s.lower())
        s = re.sub(r"http\S+|www\S+", " ", s)
        s = re.sub(r"[\w.-]+@[\w.-]+", " ", s)
        s = re.sub(r"\d+", " ", s)
        s = re.sub(r"[^\w\s√°√†·∫£√£·∫°ƒÉ·∫±·∫Ø·∫≥·∫µ·∫∑√¢·∫ß·∫•·∫©·∫´·∫≠√©√®·∫ª·∫Ω·∫π√™·ªÅ·∫ø·ªÉ·ªÖ·ªá√≠√¨·ªâƒ©·ªã√≥√≤·ªè√µ·ªç√¥·ªì·ªë·ªï·ªó·ªô∆°·ªù·ªõ·ªü·ª°·ª£√∫√π·ªß≈©·ª•∆∞·ª´·ª©·ª≠·ªØ·ª±√Ω·ª≥·ª∑·ªπ·ªµƒë]", " ", s, flags=re.I)
        s = re.sub(r"\s+", " ", s).strip()
        return s

    text_cols = [c for c in hotel_info.columns if "Description" in c]
    hotel_info["_text_info"] = (hotel_info[text_cols].astype(str).agg(" ".join, axis=1) if text_cols else "")
    corpus = hotel_info["_text_info"].map(simple_clean).fillna("")
    
    tfidf = TfidfVectorizer(max_features=40000, ngram_range=(1, 2), min_df=2)
    X = tfidf.fit_transform(corpus)
    cos_sim_matrix = cosine_similarity(X)
    return cos_sim_matrix

@st.cache_resource
def load_embeddings(model_name):
    """T·∫£i c√°c file embedding ƒë√£ ƒë∆∞·ª£c t√≠nh to√°n tr∆∞·ªõc."""
    models_dir = Path("./output/models")
    try:
        embeddings = np.load(models_dir / f"{model_name}_emb.npy")
        return embeddings
    except FileNotFoundError:
        return None

def get_recommendations(sim_matrix, hotel_df, selected_hotel_id, id_col, name_col, top_n=10):
    """L·∫•y danh s√°ch g·ª£i √Ω t·ª´ ma tr·∫≠n t∆∞∆°ng ƒë·ªìng."""
    try:
        idx = hotel_df.index[hotel_df[id_col] == selected_hotel_id][0]
        sim_scores = sim_matrix[idx]
        
        top_indices = np.argsort(-sim_scores)[:top_n + 1]
        
        recs = hotel_df.iloc[top_indices][[id_col, name_col]].copy()
        recs["similarity"] = sim_scores[top_indices]
        
        # Lo·∫°i b·ªè ch√≠nh kh√°ch s·∫°n ƒë√£ ch·ªçn v√† l·∫•y top N
        recs = recs[recs[id_col] != selected_hotel_id].head(top_n)
        recs.rename(columns={"similarity": "ƒê·ªô t∆∞∆°ng ƒë·ªìng"}, inplace=True)
        return recs
    except (IndexError, KeyError):
        return pd.DataFrame()

# --- Giao di·ªán ch√≠nh c·ªßa ·ª©ng d·ª•ng ---

st.title("üéì ƒê·ªì √Ån T·ªët Nghi·ªáp - Project 2")
st.subheader("üè® H·ªá th·ªëng G·ª£i √Ω Kh√°ch s·∫°n Agoda")
st.markdown("Ch·ªçn m·ªôt ph∆∞∆°ng ph√°p v√† m·ªôt kh√°ch s·∫°n ƒë·ªÉ xem c√°c g·ª£i √Ω t∆∞∆°ng t·ª±.")

# T·∫£i d·ªØ li·ªáu
hotel_info, HOTEL_ID_COL, HOTEL_NAME_COL = load_data()

# --- Sidebar cho c√°c t√πy ch·ªçn ---
with st.sidebar:
    st.image("logo.png", width=100) # Th√™m logo (ƒë·∫£m b·∫£o file logo.png ·ªü c√πng th∆∞ m·ª•c)
    st.title("‚öôÔ∏è T√πy ch·ªçn")
    method = st.selectbox(
        "Ch·ªçn ph∆∞∆°ng ph√°p g·ª£i √Ω:",
        ["TF-IDF", "Doc2Vec", "SBERT", "ALS"]
    )

# --- Khu v·ª±c ch√≠nh ---
st.header("1. Ch·ªçn kh√°ch s·∫°n b·∫°n th√≠ch")
hotel_list = hotel_info[HOTEL_NAME_COL].astype(str).unique().tolist()
seed_hotel_name = st.selectbox("", hotel_list)

# Hi·ªÉn th·ªã th√¥ng tin kh√°ch s·∫°n ƒë√£ ch·ªçn
if seed_hotel_name:
    selected_hotel_info = hotel_info[hotel_info[HOTEL_NAME_COL] == seed_hotel_name].iloc[0]
    seed_hotel_id = selected_hotel_info[HOTEL_ID_COL]
    
    with st.expander("Th√¥ng tin kh√°ch s·∫°n ƒë√£ ch·ªçn"):
        st.subheader(selected_hotel_info[HOTEL_NAME_COL])
        if 'Hotel_Rank' in selected_hotel_info and pd.notna(selected_hotel_info['Hotel_Rank']):
            st.write(f"**H·∫°ng:** {selected_hotel_info['Hotel_Rank']}")
        if 'Hotel_Address' in selected_hotel_info and pd.notna(selected_hotel_info['Hotel_Address']):
            st.write(f"**ƒê·ªãa ch·ªâ:** {selected_hotel_info['Hotel_Address']}")
        if '_text_info' in selected_hotel_info and selected_hotel_info['_text_info']:
            st.caption(selected_hotel_info['_text_info'][:300] + "...")

st.header("2. K·∫øt qu·∫£ ƒë·ªÅ xu·∫•t")

# --- Logic x·ª≠ l√Ω v√† hi·ªÉn th·ªã k·∫øt qu·∫£ ---
if method == "TF-IDF":
    with st.spinner("ƒêang t√≠nh to√°n ƒë·ªô t∆∞∆°ng ƒë·ªìng TF-IDF..."):
        cos_sim_matrix = preprocess_and_tfidf(hotel_info, HOTEL_ID_COL, HOTEL_NAME_COL)
        recommendations = get_recommendations(cos_sim_matrix, hotel_info, seed_hotel_id, HOTEL_ID_COL, HOTEL_NAME_COL)
    st.success(f"Top 10 kh√°ch s·∫°n t∆∞∆°ng t·ª± **{seed_hotel_name}** theo TF-IDF:")
    st.dataframe(recommendations, use_container_width=True)

elif method == "Doc2Vec":
    with st.spinner("ƒêang t·∫£i embedding Doc2Vec v√† t√¨m g·ª£i √Ω..."):
        d2v_emb = load_embeddings("d2v")
        if d2v_emb is not None:
            sim_scores = cosine_similarity([d2v_emb[hotel_info.index[hotel_info[HOTEL_ID_COL] == seed_hotel_id][0]]], d2v_emb)
            recommendations = get_recommendations(sim_scores, hotel_info, seed_hotel_id, HOTEL_ID_COL, HOTEL_NAME_COL)
            st.success(f"Top 10 kh√°ch s·∫°n t∆∞∆°ng t·ª± **{seed_hotel_name}** theo Doc2Vec:")
            st.dataframe(recommendations, use_container_width=True)
        else:
            st.warning("M√¥ h√¨nh Doc2Vec ch∆∞a s·∫µn s√†ng. Vui l√≤ng ch·∫°y notebook ƒë·ªÉ t·∫°o file embedding.")

elif method == "SBERT":
    with st.spinner("ƒêang t·∫£i embedding SBERT v√† t√¨m g·ª£i √Ω..."):
        sbert_emb = load_embeddings("sbert")
        if sbert_emb is not None:
            sim_scores = cosine_similarity([sbert_emb[hotel_info.index[hotel_info[HOTEL_ID_COL] == seed_hotel_id][0]]], sbert_emb)
            recommendations = get_recommendations(sim_scores, hotel_info, seed_hotel_id, HOTEL_ID_COL, HOTEL_NAME_COL)
            st.success(f"Top 10 kh√°ch s·∫°n t∆∞∆°ng t·ª± **{seed_hotel_name}** theo SBERT:")
            st.dataframe(recommendations, use_container_width=True)
        else:
            st.warning("M√¥ h√¨nh SBERT ch∆∞a s·∫µn s√†ng. Vui l√≤ng ch·∫°y notebook ƒë·ªÉ t·∫°o file embedding.")

elif method == "ALS":
    st.subheader("Nh·∫≠p User ID ƒë·ªÉ nh·∫≠n g·ª£i √Ω:")
    user_id = st.number_input("User ID:", min_value=0, step=1, value=0)

    if st.button("L·∫•y g·ª£i √Ω cho User"):
        with st.spinner("ƒêang kh·ªüi t·∫°o Spark v√† t·∫£i m√¥ h√¨nh ALS..."):
            try:
                import findspark
                findspark.init()
                from pyspark.sql import SparkSession
                from pyspark.ml.recommendation import ALSModel

                spark = SparkSession.builder \
                    .appName("AgodaALSInference") \
                    .master("local[*]") \
                    .getOrCreate()
                
                model_path = str(Path("./output/models/best_als_model"))
                model = ALSModel.load(model_path)
                
                user_df = spark.createDataFrame([(user_id,)], ["userId"])
                recs = model.recommendForUserSubset(user_df, 10).toPandas()
                
                if recs.empty:
                    st.info(f"Kh√¥ng c√≥ g·ª£i √Ω n√†o cho User ID: {user_id}")
                else:
                    rows = []
                    for item in recs["recommendations"].iloc[0]:
                        rows.append({"itemId": item["itemId"], "score": float(item["rating"])})
                    
                    out_df = pd.DataFrame(rows)
                    
                    # Map itemId v·ªÅ th√¥ng tin kh√°ch s·∫°n
                    id_map = hotel_info[[HOTEL_ID_COL]].reset_index().rename(columns={'index': 'itemId'})
                    id_map[HOTEL_ID_COL] = id_map[HOTEL_ID_COL].astype(str)
                    
                    # T·∫°o dataframe map gi·ªØa itemId v√† hotel_info
                    hotel_comments = pd.read_csv(Path("./data/hotel_comments.csv"))
                    user_col = [c for c in hotel_comments.columns if "Reviewer Name" in c][0]
                    hotel_col = [c for c in hotel_comments.columns if "Hotel ID" in c][0]
                    
                    item_id_map = pd.DataFrame({
                        'itemId': pd.factorize(hotel_comments[hotel_col])[0],
                        HOTEL_ID_COL: hotel_comments[hotel_col]
                    }).drop_duplicates()

                    out_df = out_df.merge(item_id_map, on="itemId", how="left")
                    out_df = out_df.merge(hotel_info[[HOTEL_ID_COL, HOTEL_NAME_COL]], on=HOTEL_ID_COL, how="left")
                    
                    st.success(f"Top 10 g·ª£i √Ω cho User ID: {user_id}")
                    st.dataframe(out_df[[HOTEL_NAME_COL, 'score']], use_container_width=True)

                spark.stop()
            except Exception as e:
                st.error(f"L·ªói: M√¥ h√¨nh ALS ch∆∞a s·∫µn s√†ng ho·∫∑c c√≥ l·ªói x·∫£y ra. Vui l√≤ng ch·∫°y notebook ƒë·ªÉ t·∫°o m√¥ h√¨nh.")
                st.error(str(e))
                if 'spark' in locals():
                    spark.stop()